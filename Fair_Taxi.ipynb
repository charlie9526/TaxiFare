{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fair_Taxi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmm7wBlxGQH9xFiVg23LVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlie9526/TaxiFare/blob/master/Fair_Taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sODayNcSk0I",
        "colab_type": "text"
      },
      "source": [
        "## Inports and Mounting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqxim_vdSo2D",
        "colab_type": "code",
        "outputId": "505410bc-6130-4b17-9b36-dc3722435135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# best_rf_yet = {'esti__bootstrap': False,\n",
        "#  'esti__max_depth': 67,\n",
        "#  'esti__max_features': 'sqrt',\n",
        "#  'esti__min_samples_leaf': 2,\n",
        "#  'esti__min_samples_split': 5,\n",
        "#  'esti__n_estimators': 1621}\n",
        "#\n",
        "# 'esti__bootstrap': False,\n",
        "#  'esti__max_depth': 52,\n",
        "#  'esti__max_features': 'sqrt',\n",
        "#  'esti__min_samples_leaf': 1,\n",
        "#  'esti__min_samples_split': 5,\n",
        "#  'esti__n_estimators': 484"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgG_U0EgS3f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import random\n",
        "from google.colab import files\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)              #data visualization library based on matplotlib\n",
        "import numpy as np                  #support library for amtrices etc.\n",
        "from scipy.stats import norm   \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   #manage warnings\n",
        "%matplotlib inline                  \n",
        "#magic function in ipynb. ploting the graphs inline after the code\n",
        "from math import sin, cos, sqrt, atan2, radians\n",
        "\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder,LabelBinarizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhmr0pfzTNr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/FAIR_TAXI/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/FAIR_TAXI/test.csv')\n",
        "trip_id  = test_df['tripid']\n",
        "\n",
        "sample_submission_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/FAIR_TAXI/sample_submission.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1dGLTTmQgDV",
        "colab_type": "text"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3TzpMDUQjU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#elts write a lambda function\n",
        "def get_duration(x):\n",
        "  if x['pickup_time']==None or x['drop_time']==None:\n",
        "    return None\n",
        "  \n",
        "  try :\n",
        "    if int(x['pickup_time'].split(\"/\")[1])>12 or int(x['drop_time'].split(\"/\")[1])>12:\n",
        "      gap = datetime.strptime(x['pickup_time'],\"%m/%d/%Y %H:%M\")-datetime.strptime(x['drop_time'],\"%m/%d/%Y %H:%M\")\n",
        "    else:\n",
        "      if int(x['pickup_time'].split(\"/\")[1]) != int(x['drop_time'].split(\"/\")[1]):\n",
        "        gap = datetime.strptime(x['pickup_time'],\"%m/%d/%Y %H:%M\")-datetime.strptime(x['drop_time'],\"%m/%d/%Y %H:%M\")\n",
        "      else:\n",
        "        gap = datetime.strptime(x['pickup_time'],\"%d/%m/%Y %H:%M\")-datetime.strptime(x['drop_time'],\"%d/%m/%Y %H:%M\")\n",
        "    # print (gap.total_seconds()/3600,x['pickup_time'] ,x['drop_time'])\n",
        "  except :\n",
        "    # print(int(x['pickup_time'].split(\"/\")[0])>12 or int(x['drop_time'].split(\"/\")[0])>12)\n",
        "    return None\n",
        "  # print(abs(gap.total_seconds()/3600), x['drop_time'],x['pickup_time'])\n",
        "  return abs(gap.total_seconds())\n",
        "\n",
        "class MakeTripDurationFeature(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X['time_gap'] = X.apply(lambda x:get_duration(x), axis=1)\n",
        "        X = X.drop(labels=['pickup_time','drop_time'],axis=1)\n",
        "        return X\n",
        "\n",
        "# Change the label of binary values\n",
        "class MakeTripDurationFeature(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y):\n",
        "        y = y.apply(lambda x:get_binary(x))\n",
        "        # print (y);\n",
        "        return self\n",
        "    def transform(self,X):\n",
        "        return X\n",
        "\n",
        "# debugerr \n",
        "class debugerr(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y):\n",
        "        print (pd.DataFrame(X));\n",
        "        return self\n",
        "    def transform(self,X):\n",
        "        return X\n",
        "\n",
        "# lambda function for change label\n",
        "def get_binary(x):\n",
        "  if x==None:\n",
        "    return 0\n",
        "  if x == \"correct\":\n",
        "    # print (x);\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# set distance column\n",
        "class set_distance(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "    def transform(self, X):\n",
        "      X['distance'] = X.apply(lambda x:get_distance(x), axis=1)\n",
        "      # print(X)\n",
        "      # X = X.drop(labels=['pick_lat','pick_lon','drop_lat','drop_lon'],axis=1)\n",
        "      return X\n",
        "# lambda column get distance\n",
        "def get_distance(x):\n",
        "  R = 6373.0\n",
        "  lat1 = radians(float(x['drop_lat']))\n",
        "  lon1 = radians(float(x['drop_lon']))\n",
        "  lat2 = radians(float(x['pick_lat']))\n",
        "  lon2 = radians(float(x['pick_lon']))\n",
        "\n",
        "  dlon = lon2 - lon1\n",
        "  dlat = lat2 - lat1\n",
        "\n",
        "  a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "  c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "  distance = R * c\n",
        "  return distance\n",
        "\n",
        "# remove columns\n",
        "class remove_colums_unwanted(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "    def transform(self, X):\n",
        "      X = X.drop(labels=['pick_lat','pick_lon','drop_lat','drop_lon'],axis=1)\n",
        "      return X\n",
        "\n",
        "\n",
        "def encoding_label(label):\n",
        "  if(label=='correct'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def get_hour_value(x,date_time_column_name):\n",
        "  if x[date_time_column_name]==None:\n",
        "    return None\n",
        "  return datetime.strptime(x[date_time_column_name],\"%m/%d/%Y %H:%M\").hour\n",
        "\n",
        "################### Here we have to add fare_per_hour column\n",
        "################### write a lambda function\n",
        "\n",
        "def get_fare_per_min(x):\n",
        "  if x[\"fare\"]>=0 and x[\"duration\"]>0:\n",
        "    minutes = x[\"duration\"]/60.0\n",
        "    val = x['fare']/minutes\n",
        "    return val\n",
        "  if x[\"duration\"]==0:\n",
        "    return 0\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILSYtEYrqsLE",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzHTTaaRqz03",
        "colab_type": "text"
      },
      "source": [
        "check null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-XLgDuOxRnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df = train_df.dropna(subset=['fare'])\n",
        "train_df['fare'].fillna(0,inplace=True)\n",
        "test_df['fare'].fillna(0,inplace=True)\n",
        "train_df['additional_fare'].fillna(0,inplace=True)\n",
        "test_df['additional_fare'].fillna(0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD4GHS8XdDT5",
        "colab_type": "text"
      },
      "source": [
        "encode label and create feature set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S40RvNkdF-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['label'] = train_df['label'].apply(encoding_label).values\n",
        "features_df = train_df.loc[:, train_df.columns != 'label']\n",
        "label_df = train_df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAjngFaidHt-",
        "colab_type": "text"
      },
      "source": [
        "remove unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L--k8x5dYvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_df = features_df.loc[:, features_df.columns != 'tripid']\n",
        "test_df = test_df.loc[:, test_df.columns != 'tripid']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhp6ma5xdpiw",
        "colab_type": "text"
      },
      "source": [
        "add some columns to dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFRL6gnidozS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_df['fare_per_min'] = features_df.apply(lambda x:get_fare_per_min(x),axis=1 )\n",
        "test_df['fare_per_min'] = test_df.apply(lambda x:get_fare_per_min(x),axis=1 )\n",
        "\n",
        "features_df['distance'] = features_df.apply(lambda x:get_distance(x), axis=1)\n",
        "test_df['distance'] = test_df.apply(lambda x:get_distance(x), axis=1)\n",
        "\n",
        "features_df = features_df.drop(labels=['drop_lat','drop_lon','pickup_time','pick_lat','pick_lon','drop_time'],axis=1)\n",
        "test_df = test_df.drop(labels=['drop_lat','drop_lon','pickup_time','pick_lat','pick_lon','drop_time'],axis=1)\n",
        "\n",
        "features_df.to_csv(\"/content/drive/My Drive/Colab Notebooks/FAIR_TAXI/features_df.csv\", index=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezw2HIfRelEn",
        "colab_type": "text"
      },
      "source": [
        "split train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uchXS5kFebeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features_df, label_df, test_size=0.3, random_state=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaxC76-gUItP",
        "colab_type": "text"
      },
      "source": [
        "## Model Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHHO_y2EW11i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "85d82f36-3be8-471e-f18a-f9066faa08e6"
      },
      "source": [
        "\n",
        "numeric_preprocessing_steps = Pipeline([\n",
        "    ('standard_scaler', StandardScaler()),\n",
        "    ('simple_imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "numeric_cols = features_df.columns[features_df.dtypes != \"object\"].values\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "        (\"numeric\", numeric_preprocessing_steps, numeric_cols)\n",
        "    ],\n",
        "    remainder = \"drop\"\n",
        ")\n",
        "print(numeric_cols)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['additional_fare' 'duration' 'meter_waiting' 'meter_waiting_fare'\n",
            " 'meter_waiting_till_pickup' 'fare' 'fare_per_min' 'distance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXeGjXWmetcn",
        "colab_type": "text"
      },
      "source": [
        "create random grid search cv for random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BsbF-RxBEWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestClassifier(random_state = 42)\n",
        "\n",
        "\n",
        "# # Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 20)]\n",
        "# # Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 15)]\n",
        "max_depth.append(None)\n",
        "# # Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10, 20]\n",
        "# # Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4 , 10]\n",
        "# # Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "random_grid = {\n",
        "               'esti__n_estimators': n_estimators,\n",
        "               'esti__max_features': max_features,\n",
        "               'esti__max_depth': max_depth,\n",
        "               'esti__min_samples_split': min_samples_split,\n",
        "               'esti__min_samples_leaf': min_samples_leaf,\n",
        "               'esti__bootstrap': bootstrap\n",
        "               }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-cJtNGNgonf",
        "colab_type": "text"
      },
      "source": [
        "RF: 0.974812 (0.002197)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_F0ntgnsTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pca = PCA()\n",
        "# estimators = SVC(kernel =\"rgf\", gamma=0.1 , C=5)\n",
        "\n",
        "estimators = RandomForestClassifier(\n",
        "      # bootstrap= False,\n",
        "      random_state=1,\n",
        "      max_depth=70,\n",
        "      max_features= 'sqrt',\n",
        "      # min_samples_leaf= 2,\n",
        "      # min_samples_split=3,\n",
        "      n_estimators = 1621\n",
        ")\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "                          (\"preprocessor\", preprocessor),\n",
        "                          # (\"debuffe\",debugerr()),\n",
        "                          (\"pca\",pca),\n",
        "                          (\"esti\", estimators)\n",
        "                          ])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZKieZgHZ9e_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59c21d2a-7eb9-4404-f9fc-114b9a482be8"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "cv_results = cross_val_score(full_pipeline, features_df, label_df, cv=kfold, scoring='f1')\n",
        "print('%s: %f (%f)' % (\"RF\", cv_results.mean(), cv_results.std()))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF: 0.974947 (0.002026)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDkQGAm1aEBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rf_random_pipe = RandomizedSearchCV(full_pipeline, param_distributions = random_grid, cv = 10, verbose=2, random_state=42, scoring ='f1')\n",
        "# rf_random_pipe.fit(features_df,label_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcqAya5DmMDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "2c1b9346-7092-4697-9d69-6c8646ac97d1"
      },
      "source": [
        "full_pipeline.fit(X_train,y_train)\n",
        "predicted = full_pipeline.predict(test_df)\n",
        "data_dict = { 'tripid':trip_id, 'prediction':predicted}\n",
        "pd_test_result = pd.DataFrame(data=data_dict)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f46b6a7eb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'tripid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrip_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prediction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd_test_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'full_pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTw4CryXbAxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd_test_result[['tripid','prediction']].to_csv(\"/content/drive/My Drive/Colab Notebooks/FAIR_TAXI/result.csv\", index=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}